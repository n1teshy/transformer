{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "from core.models import Generator\n",
    "from core.utils.bpe import Tokenizer\n",
    "from core.utils.configs import ModelConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_SZ = 32\n",
    "MAX_GENERATION = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.load(\"tokenizer/poet2_tokenizer.model\")\n",
    "\n",
    "model_config = ModelConfig(\n",
    "    no_blocks=1,\n",
    "    no_heads=1,\n",
    "    model_dim=32,\n",
    "    vocab_size=tokenizer.size,\n",
    "    pad_id=tokenizer.pad_id,\n",
    "    context=32,\n",
    "    dropout=0.2,\n",
    "    train_mode=True,\n",
    ")\n",
    "model = Generator(model_config)\n",
    "optimizer = AdamW(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.06051778793335\n",
      "6.680383205413818\n",
      "6.391345024108887\n",
      "6.121426582336426\n",
      "5.810373783111572\n",
      "5.499338626861572\n",
      "5.198443412780762\n",
      "4.704003810882568\n",
      "4.2939653396606445\n",
      "4.1580491065979\n",
      "4.1385650634765625\n",
      "3.6034114360809326\n",
      "3.2370765209198\n",
      "2.9886231422424316\n",
      "2.7105906009674072\n",
      "2.561103343963623\n",
      "2.135735511779785\n",
      "1.6755222082138062\n",
      "1.7410500049591064\n",
      "1.4514174461364746\n",
      "1.1960655450820923\n",
      "1.0218751430511475\n",
      "0.8699359893798828\n",
      "0.5150958299636841\n",
      "0.617453396320343\n",
      "0.5127629637718201\n",
      "0.45485353469848633\n",
      "0.375817209482193\n",
      "0.24338391423225403\n",
      "0.3035971224308014\n",
      "0.3195395767688751\n",
      "0.2480405867099762\n",
      "0.14307436347007751\n",
      "0.1470261812210083\n",
      "0.11628586053848267\n",
      "0.10533006489276886\n",
      "0.1357780396938324\n",
      "0.07618315517902374\n",
      "0.1073233038187027\n",
      "0.1141652911901474\n",
      "0.09436477720737457\n",
      "0.10552819818258286\n",
      "0.09733698517084122\n",
      "0.0439443401992321\n",
      "0.057830214500427246\n",
      "0.06800628453493118\n",
      "0.0713738352060318\n",
      "0.06710392981767654\n",
      "0.051266591995954514\n",
      "0.07144732773303986\n",
      "0.049634285271167755\n",
      "0.041557639837265015\n",
      "0.055714406073093414\n",
      "0.04485560208559036\n",
      "0.041841764003038406\n",
      "0.03791559860110283\n",
      "0.02918723225593567\n",
      "0.06044728308916092\n",
      "0.03772834315896034\n",
      "0.045738134533166885\n",
      "0.03663156181573868\n",
      "0.03443485498428345\n",
      "0.028056982904672623\n",
      "0.06325186789035797\n",
      "0.02637966349720955\n",
      "0.029756253585219383\n",
      "0.04027068614959717\n",
      "0.03079356625676155\n",
      "0.03006104752421379\n",
      "0.018412146717309952\n",
      "0.03656376153230667\n",
      "0.024649007245898247\n",
      "0.032614126801490784\n",
      "0.03178878501057625\n",
      "0.03634977340698242\n",
      "0.028824886307120323\n",
      "0.027177870273590088\n",
      "0.023064248263835907\n",
      "0.029131973162293434\n",
      "0.018532751128077507\n",
      "0.018250931054353714\n",
      "0.02779214456677437\n",
      "0.016486171633005142\n",
      "0.017072608694434166\n",
      "0.025230497121810913\n",
      "0.019877377897500992\n",
      "0.028216242790222168\n",
      "0.020472358912229538\n",
      "0.01797584816813469\n",
      "0.017743375152349472\n",
      "0.01747930608689785\n",
      "0.0359797403216362\n",
      "0.01914016529917717\n",
      "0.0262192003428936\n",
      "0.024121593683958054\n",
      "0.018949974328279495\n",
      "0.02304081991314888\n",
      "0.016183244064450264\n",
      "0.020190078765153885\n",
      "0.020994199439883232\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "for _ in range(100):\n",
    "    _, loss = model(\n",
    "        torch.tensor([list(range(10))]), torch.tensor([list(range(1, 11))])\n",
    "    )\n",
    "    print(loss.item())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
