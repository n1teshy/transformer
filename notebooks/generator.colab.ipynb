{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/n1teshy/transformer > /dev/null\n",
    "!mv transformer/* . && rmdir transformer\n",
    "!mkdir -p drive/MyDrive/checkpoints/poet2\n",
    "!ls drive/MyDrive/checkpoints/poet2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'core'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AdamW\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgenerator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GeneratorDataset\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Generator\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbpe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tokenizer\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'core'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from core.data.generator import GeneratorDataset\n",
    "from core.models import Generator\n",
    "from core.utils.bpe import Tokenizer\n",
    "from core.utils.configs import DecoderConfig, GeneratorDataConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data conf\n",
    "batch_size = 64\n",
    "context = 512\n",
    "train_cache = \"drive/MyDrive/datasets/poems_cache_34k/train\"\n",
    "val_cache = \"drive/MyDrive/datasets/poems_cache_34k/val\"\n",
    "sample_delimiter = (\"# \" * 39) + \"#\"\n",
    "\n",
    "# model conf\n",
    "no_blocks = 3\n",
    "no_heads = 8\n",
    "model_dim = 768\n",
    "model_context = 512\n",
    "\n",
    "# training conf\n",
    "epochs = 10\n",
    "learning_rate = 0.001\n",
    "checkpoints_dir = \"drive/MyDrive/checkpoints/poet2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.load(\"tokenizer/poet2_tokenizer.model\")\n",
    "\n",
    "train_data_conf = GeneratorDataConfig(\n",
    "    batch_size=batch_size, pad_id=tokenizer.pad_id, cache_dir=train_cache\n",
    ")\n",
    "val_data_conf = GeneratorDataConfig(\n",
    "    batch_size=batch_size, pad_id=tokenizer.pad_id, cache_dir=val_cache\n",
    ")\n",
    "\n",
    "train_dataset = GeneratorDataset(train_data_conf)\n",
    "val_dataset = GeneratorDataset(val_data_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conf = DecoderConfig(\n",
    "    no_blocks=no_blocks,\n",
    "    no_heads=no_heads,\n",
    "    model_dim=model_dim,\n",
    "    vocab_size=tokenizer.size,\n",
    "    pad_id=tokenizer.pad_id,\n",
    "    context=model_context,\n",
    "    dropout=0.2,\n",
    "    train_mode=True,\n",
    "    sos_id=tokenizer.sos_id,\n",
    "    eos_id=tokenizer.eos_id,\n",
    ")\n",
    "model = Generator(model_conf)\n",
    "# model.load_state_dict(torch.load())\n",
    "model = model.to(\"cuda\")\n",
    "print(\n",
    "    \"model has %.2fmn parameters\"\n",
    "    % (sum(p.numel() for p in model.parameters()) / 1e6,)\n",
    ")\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_val_loss() -> float:\n",
    "    model.eval()\n",
    "    batch = val_dataset.next_batch()\n",
    "    if batch is None:\n",
    "        val_dataset.reset()\n",
    "        batch = val_dataset.next_batch()\n",
    "    x, y = batch\n",
    "    _, loss = model(x, y)\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def save_model(t_loss: float, v_loss: float):\n",
    "    name = \"%.2f-%.2f-%.2f-%d-%d-%d-%d.pth\" % (\n",
    "        t_loss,\n",
    "        v_loss,\n",
    "        learning_rate,\n",
    "        no_blocks,\n",
    "        no_heads,\n",
    "        model_dim,\n",
    "        model_context,\n",
    "    )\n",
    "    torch.save(model.state_dict(), os.path.join(checkpoints_dir, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'epochs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m best_t_loss, best_v_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4.5\u001b[39m, \u001b[38;5;241m4.5\u001b[39m\n\u001b[0;32m      2\u001b[0m loss_window \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[43mepochs\u001b[49m):\n\u001b[0;32m      4\u001b[0m     batches_processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m batch \u001b[38;5;241m:=\u001b[39m train_dataset\u001b[38;5;241m.\u001b[39mnext_batch():\n",
      "\u001b[1;31mNameError\u001b[0m: name 'epochs' is not defined"
     ]
    }
   ],
   "source": [
    "best_t_loss, best_v_loss = 4, 4\n",
    "min_loss_improv, loss_window = 0.2, 128\n",
    "mt_loss, mv_loss = None, None\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    batches_processed = 0\n",
    "    while batch := train_dataset.next_batch():\n",
    "        model.train()\n",
    "        x, y = batch\n",
    "        _, loss = model(x, y)\n",
    "        batches_processed += 1\n",
    "        t_loss, v_loss = loss.item(), get_val_loss()\n",
    "        mt_loss = t_loss * (1/loss_window) + (mt_loss or t_loss) * (1 - 1/loss_window)\n",
    "        mv_loss = v_loss * (1/loss_window) + (mv_loss or v_loss) * (1 - 1/loss_window)\n",
    "        print(\n",
    "            \"%d-%d. t-loss: %.2f -> %.2f, v-loss: %.2f -> %.2f\"\n",
    "            % (epoch, batches_processed, t_loss, mt_loss, v_loss, mv_loss)\n",
    "        )\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (\n",
    "            batches_processed >= loss_window\n",
    "            and best_t_loss - mt_loss >= min_loss_improv\n",
    "            and mv_loss - mt_loss < min_loss_improv\n",
    "        ):\n",
    "            save_model(mt_loss, mv_loss)\n",
    "            best_t_loss, best_v_loss = mt_loss, mv_loss\n",
    "            print(\"saved with losses: %.2f, %.2f\" % (mt_loss, mv_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in model.generate():\n",
    "  print(tokenizer.decode([token]), end=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
